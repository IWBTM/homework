

## 3.8



a. Any path, no matter how bad it appears, might lead to an arbitrarily large reward (negative cost). Therefore, one would need to exhaust all possible paths to be sure of finding the best one.

b. . Suppose the greatest possible reward is c. Then if we also know the maximum depth of the state space, then any path with d levels remaining can be improved by at most cd, so any paths worse than cd less than the best path can be pruned. For state spaces with loops, this guarantee doesn√≠t help, because it is possible

to go around a loop any number of times, picking up c reward each time

c. The agent will go around the circle forever.

d. Although the scene is beautiful, seeing too much times of it is boring. So people will not see it forever. To solve this problem, we can create a state space to record the places that has been visited to avoid running alone the circle.

e. Real domains with looping behavior include eating junk food and going to class.



## 3.14



a. false, because if we expand a right path at the first time, the path may be shorter than A*

b. True, that means f(n)=g(n), which rely the f(n) totally.

c. True, A* is used in discretized space

d. true,depth of the solution matters for breadth-first search, not cost.

e. false, because a rook cannot move across other piece.

## 3.19

Both of the BFS and DFS are ok. The web group is just a map which don't have any different with other maps. So we also can use  bidirectional search.